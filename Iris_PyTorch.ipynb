{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file):\n",
    "    df=pd.read_csv(file,names=[0,1,2,3,4])\n",
    "    d={'Iris-setosa':0,'Iris-virginica':2,'Iris-versicolor':1}\n",
    "    df[4]=df[4].map(d)\n",
    "    X=df.iloc[:,0:4]\n",
    "    y=df.iloc[:,4:]\n",
    "    X=np.array(X)\n",
    "    y=np.array(y)\n",
    "    y = np.reshape(y,(-1,1))\n",
    "    ss=StandardScaler().fit(X)\n",
    "    X=ss.transform(X)\n",
    "    X=np.array(X,dtype='float32')\n",
    "    y=np.array(y,dtype='int32')\n",
    "    return train_test_split(X,y,test_size=0.7,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=get_data('d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 1e-2\n",
    "num_epoches = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuralnetwork(nn.Module):\n",
    "    def __init__(self, in_dim, n_hidden_1, n_hidden_2, out_dim):\n",
    "        super(Neuralnetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(in_dim, n_hidden_1)\n",
    "        self.layer2 = nn.Linear(n_hidden_1, n_hidden_2)\n",
    "        self.layer3 = nn.Linear(n_hidden_2, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Neuralnetwork(4, 20, 16, 3)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/50] Loss: 0.002087, Acc: 1.000000\n",
      "[2/50] Loss: 0.002064, Acc: 1.000000\n",
      "[3/50] Loss: 0.002042, Acc: 1.000000\n",
      "[4/50] Loss: 0.002021, Acc: 1.000000\n",
      "[5/50] Loss: 0.002001, Acc: 1.000000\n",
      "[6/50] Loss: 0.001981, Acc: 1.000000\n",
      "[7/50] Loss: 0.001963, Acc: 1.000000\n",
      "[8/50] Loss: 0.001945, Acc: 1.000000\n",
      "[9/50] Loss: 0.001928, Acc: 1.000000\n",
      "[10/50] Loss: 0.001911, Acc: 1.000000\n",
      "[11/50] Loss: 0.001896, Acc: 1.000000\n",
      "[12/50] Loss: 0.001881, Acc: 1.000000\n",
      "[13/50] Loss: 0.001866, Acc: 1.000000\n",
      "[14/50] Loss: 0.001852, Acc: 1.000000\n",
      "[15/50] Loss: 0.001839, Acc: 1.000000\n",
      "[16/50] Loss: 0.001826, Acc: 1.000000\n",
      "[17/50] Loss: 0.001813, Acc: 1.000000\n",
      "[18/50] Loss: 0.001801, Acc: 1.000000\n",
      "[19/50] Loss: 0.001789, Acc: 1.000000\n",
      "[20/50] Loss: 0.001778, Acc: 1.000000\n",
      "[21/50] Loss: 0.001767, Acc: 1.000000\n",
      "[22/50] Loss: 0.001757, Acc: 1.000000\n",
      "[23/50] Loss: 0.001747, Acc: 1.000000\n",
      "[24/50] Loss: 0.001737, Acc: 1.000000\n",
      "[25/50] Loss: 0.001728, Acc: 1.000000\n",
      "[26/50] Loss: 0.001719, Acc: 1.000000\n",
      "[27/50] Loss: 0.001710, Acc: 1.000000\n",
      "[28/50] Loss: 0.001701, Acc: 1.000000\n",
      "[29/50] Loss: 0.001693, Acc: 1.000000\n",
      "[30/50] Loss: 0.001685, Acc: 1.000000\n",
      "[31/50] Loss: 0.001677, Acc: 1.000000\n",
      "[32/50] Loss: 0.001670, Acc: 1.000000\n",
      "[33/50] Loss: 0.001662, Acc: 1.000000\n",
      "[34/50] Loss: 0.001655, Acc: 1.000000\n",
      "[35/50] Loss: 0.001649, Acc: 1.000000\n",
      "[36/50] Loss: 0.001642, Acc: 1.000000\n",
      "[37/50] Loss: 0.001635, Acc: 1.000000\n",
      "[38/50] Loss: 0.001629, Acc: 1.000000\n",
      "[39/50] Loss: 0.001623, Acc: 1.000000\n",
      "[40/50] Loss: 0.001617, Acc: 1.000000\n",
      "[41/50] Loss: 0.001611, Acc: 1.000000\n",
      "[42/50] Loss: 0.001606, Acc: 1.000000\n",
      "[43/50] Loss: 0.001600, Acc: 1.000000\n",
      "[44/50] Loss: 0.001595, Acc: 1.000000\n",
      "[45/50] Loss: 0.001589, Acc: 1.000000\n",
      "[46/50] Loss: 0.001584, Acc: 1.000000\n",
      "[47/50] Loss: 0.001579, Acc: 1.000000\n",
      "[48/50] Loss: 0.001575, Acc: 1.000000\n",
      "[49/50] Loss: 0.001570, Acc: 1.000000\n",
      "[50/50] Loss: 0.001565, Acc: 1.000000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoches):\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for i in range(X_train.shape[0]):\n",
    "        acc = 0.0\n",
    "        x, y = torch.from_numpy(X_train[i]), torch.from_numpy(y_train[i]).type(torch.LongTensor)\n",
    "        if torch.cuda.is_available():\n",
    "            x = Variable(x).cuda()\n",
    "            y = Variable(y).cuda()\n",
    "        else:\n",
    "            x = Variable(x)\n",
    "            y = Variable(y)\n",
    "       \n",
    "        out = model(x).view(1,-1)\n",
    "        loss = criterion(out, y)\n",
    "    \n",
    "        pred = torch.argmax(out)\n",
    "        correct = (pred==y.data[0])\n",
    "        \n",
    "        acc += correct.item()\n",
    "        running_loss += loss * y.size(0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('[{}/{}] Loss: {:.6f}, Acc: {:.6f}'.format(\n",
    "        epoch + 1, num_epoches, running_loss / (batch_size * i),\n",
    "        acc))\n",
    "    model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50/50] Loss: 0.002896, Acc: 100.000000\n"
     ]
    }
   ],
   "source": [
    "val_acc = 0.0\n",
    "for i in range(X_test.shape[0]):\n",
    "    x, y = torch.from_numpy(X_test[i]), torch.from_numpy(y_test[i]).type(torch.LongTensor)\n",
    "    if torch.cuda.is_available():\n",
    "        x = Variable(x).cuda()\n",
    "        y = Variable(y).cuda()\n",
    "    else:\n",
    "        x = Variable(x)\n",
    "        y = Variable(y)\n",
    "\n",
    "    out = model(x).view(1,-1)\n",
    "    loss = criterion(out, y)\n",
    "\n",
    "    pred = torch.argmax(out)\n",
    "    correct = (pred==y.data[0])\n",
    "    \n",
    "    val_acc += correct.item()\n",
    "    running_loss += loss * label.size(0)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    \n",
    "print('[{}/{}] Loss: {:.6f}, Acc: {:.6f}'.format(\n",
    "    epoch + 1, num_epoches, running_loss / (batch_size * i),\n",
    "    val_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
